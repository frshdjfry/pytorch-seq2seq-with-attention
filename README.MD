# tf2-seq2seq-with-attention
modifications on omarsar notebook's:
https://github.com/omarsar/pytorch_neural_machine_translation_attention/blob/master/NMT_in_PyTorch.ipynb

cuda 10.0 (for GPU)
pytorch torch-0.4.1